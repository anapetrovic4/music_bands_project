{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"tJuiQAMObQvM"},"outputs":[],"source":["!pip install requests_html\n","from requests_html import AsyncHTMLSession\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import asyncio"]},{"cell_type":"markdown","metadata":{"id":"mXQnoJvO25sn"},"source":["### Start asynchronous HTML session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtmbf7c3bQvO"},"outputs":[],"source":["asession = AsyncHTMLSession() # Start asynchronous HTML session"]},{"cell_type":"markdown","metadata":{"id":"7ASj4_-M28-h"},"source":["### Fetch a webpage using new session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l8YH8cRcbQvO"},"outputs":[],"source":["\"\"\"\n","Asynchronous function is used to fetch a webpage using new session with retry logic\n","Parameters:\n","    - url\n","    - retries (Number of attempts to try in case of errors; default is 3)\n","\"\"\"\n","async def fetch_with_new_session(url, retries=3):\n","    for attempt in range(retries):\n","        try:\n","            response = await asession.get(url)\n","            await response.html.arender(timeout=30000) # added to increase the default 8 seconds\n","            return response.html.html\n","        except Exception as e:\n","            print(f\"attempt {attempt + 1} failed {e}\")\n","            if attempt < retries - 1:\n","                await asyncio.sleep(2)\n","            else:\n","                print(f\"all attempts failes for {url}\")\n","                raise e\n","    await asession.close()"]},{"cell_type":"markdown","metadata":{"id":"tE1M93Kh3CRa"},"source":["### Get page URL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FWqpiAALbQvO"},"outputs":[],"source":["\"\"\"\n","Asynchronous function to get page url\n","\"\"\"\n","async def get_page(url):\n","    return await fetch_with_new_session(url)"]},{"cell_type":"markdown","metadata":{"id":"xofyC8jd3GGm"},"source":["### Get all albums from artist"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Adu1RJ7UbQvO"},"outputs":[],"source":["\"\"\"\n","Asynchronous function to extract all albums from an artist's discography page.\n","  This function:\n","  1. Retrieves the page content using an asynchronous HTTP request\n","  2. Parses HTML content to identify the first <table> tag, which contains albums data\n","  3. Finds all <td> tags with class 'meta', where album links are stored\n","  4. Iterates through the anchor <a> tags to find href attributes\n","  5. Stores external (http) links into a set to avoid duplicates, then converts the set to a list\n","  6. Returns a list of all albums\n","\"\"\"\n","async def get_album(url):\n","    albums = set()\n","\n","    content = await get_page(url)\n","\n","    soup = BeautifulSoup(content, 'html.parser')\n","\n","    table = soup.find('table')\n","\n","    td_tags = table.find_all('td', class_='meta')\n","    for td in td_tags:\n","        a_tags = td.find_all('a')\n","        for a in a_tags:\n","            href = a.get('href')\n","            if href.startswith('//'):\n","                continue\n","            if href.startswith('http'):\n","                albums.add(href)\n","\n","    albums_list = list(albums)\n","\n","    return albums_list"]},{"cell_type":"markdown","metadata":{"id":"C73kxAmp3LjG"},"source":["### Get all songs from album"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8-l-UKVmbQvP"},"outputs":[],"source":["\"\"\"\n","Asynchronous function to extract all songs from album link from a list of albums.\n","  This function:\n","  1. Retrieves the page content using an asynchronous HTTP request\n","  2. Parses HTML content to identify all <div> tags with class 'disc', which contains songs data\n","  3. Finds all <div> tags with class 'title', where song titles are stored\n","  4. Iterates through the title <div> tags to find href attributes\n","  5. Stores external (http) links into a set to avoid duplicates, then converts the set to a list\n","  6. Returns a list of all albums\n","\"\"\"\n","async def get_all_songs(album):\n","    href_set = set()\n","\n","    content = await get_page(album)\n","    soup = BeautifulSoup(content, 'html.parser')\n","\n","    divs_disc = soup.find_all('div', class_='disc')\n","\n","    for div_disc in divs_disc:\n","        title_divs = div_disc.find_all('div', class_='title')\n","\n","        for title_div in title_divs:\n","            a_tags = soup.find_all('a')\n","            for a in a_tags:\n","                href = a.get('href')\n","                if 'allmusic.com/song' in href:\n","                    href_set.add(href)\n","\n","    href_list = list(href_set)\n","\n","    return href_list"]},{"cell_type":"markdown","metadata":{"id":"rxnQhwNT3OUx"},"source":["### Get all track information"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JNT170xybQvP"},"outputs":[],"source":["\"\"\"\n","Asynchronous function to extract information about the track as a dictionary: track name, composer, genres, styles, moods and themes.\n","  This function:\n","  1. Retrieves the page content using an asynchronous HTTP request\n","  2. Parses HTML content to identify all <div> tags and <h1> tag, which contain songs and title data\n","  3. Stores results in lists: composers, genres, styles, moods and themes\n","  4. Return a dictionary containing all the extracted information\n","\"\"\"\n","async def get_track_info(song):\n","\n","    content = await get_page(song)\n","    soup = BeautifulSoup(content, 'html.parser')\n","\n","    track_name_tag = soup.find('h1')\n","    track_name = track_name_tag.get_text(strip=True)\n","\n","    composers_tag = soup.find('div', class_='composer')\n","    composers = ', '.join([a.get_text(strip=True) for a in composers_tag.find_all('a')]) if composers_tag else None\n","\n","    genres_tag = soup.find('div', class_='genre')\n","    genres = ', '.join([a.get_text(strip=True) for a in genres_tag.find_all('a')]) if genres_tag else None\n","\n","    styles_tag = soup.find('div', class_='styles')\n","    styles = ', '.join([a.get_text(strip=True) for a in styles_tag.find_all('a')]) if styles_tag else None\n","\n","    moods_tag = soup.find('div', id='moodsGrid')\n","    moods_links = moods_tag.find_all('a') if moods_tag else []\n","    moods = [link.get_text(strip=True).split('(')[0].strip() for link in moods_links]\n","\n","    themes_tag = soup.find('div', id='themesGrid')\n","    themes_links = themes_tag.find_all('a') if themes_tag else []\n","    themes = [link.get_text(strip=True).split('(')[0].strip() for link in themes_links]\n","\n","    return {\n","        'track_name' : track_name,\n","        'composers' : composers,\n","        'genres' : genres,\n","        'styles' : styles,\n","        'moods' : ', ' .join(moods),\n","        'themes' : ', ' .join(themes),\n","    }"]},{"cell_type":"markdown","metadata":{"id":"vDmkYVw83RQR"},"source":["### Get all album information"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"BsV7CZ-jbQvP"},"outputs":[],"source":["\"\"\"\n","Asynchronous function to extract information about albums: album name, user rating, release date, album duration, genres, styles, recording location, recording date, moods and themes\n"," This function:\n","  1. Retrieves the page content using an asynchronous HTTP request\n","  2. Parses HTML content to identify various types of html tags, which contain album data\n","  3. Stores results in lists: rating, date, duration, album_genres, album_styles, location, recording_period, album_moods, album_themes\n","  4. Return a dictionary containing all the extracted information\n","\"\"\"\n","async def get_album_info(album):\n","\n","    content = await get_page(album)\n","    soup = BeautifulSoup(content, 'html.parser')\n","\n","    album_name = soup.find('h1')\n","\n","    user_rating = soup.find('div', class_=lambda value: value and value.startswith('averageUserRating ratingAverage'))\n","    rating_class = next((cls for cls in user_rating['class'] if cls.startswith('ratingAverage')), None)\n","    if rating_class:\n","        rating = int(rating_class.replace('ratingAverage', '').lstrip('0') or '0')\n","    else:\n","        rating = 0\n","\n","    release_date = soup.find('div', class_='release-date')\n","    date = release_date.find('span') if release_date else None\n","\n","    album_duration = soup.find('div', class_='duration')\n","    duration = album_duration.find('span') if album_duration else None\n","\n","    genres_tag = soup.find('div', class_='genre')\n","    album_genres = ', '.join([a.get_text(strip=True) for a in genres_tag.find_all('a')]) if genres_tag else None\n","\n","    styles_tag = soup.find('div', class_='styles')\n","    album_styles = ', '.join([a.get_text(strip=True) for a in styles_tag.find_all('a')]) if styles_tag else None\n","\n","    recording_location = soup.find('div', class_='recording-location')\n","    location = recording_location.find('div') if recording_location else None\n","\n","    recording_date = soup.find('div', class_='recording-date')\n","    recording_period = recording_date.find('div') if recording_date else None\n","\n","    moods_tag = soup.find('div', id='moodsGrid')\n","    moods_links = moods_tag.find_all('a') if moods_tag else []\n","    album_moods = [link.get_text(strip=True).split('(')[0].strip() for link in moods_links]\n","\n","    themes_tag = soup.find('div', id='themesGrid')\n","    themes_links = themes_tag.find_all('a') if themes_tag else []\n","    album_themes = [link.get_text(strip=True).split('(')[0].strip() for link in themes_links]\n","\n","    return {\n","        'album_name' : album_name.text if album_name else None,\n","        'user_rating' : rating,\n","        'album_release_date' : date.text if date else None,\n","        'album_duration' : duration.text if duration else None,\n","        'album_genre' : album_genres,\n","        'album_styles' : album_styles,\n","        'album_recording_location' : location.text if location else None,\n","        'album-recording-date' : recording_period.text if recording_period else None,\n","        'album_moods' : album_moods,\n","        'album_themes' : album_themes,\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BLHiiUr4yJ8C"},"outputs":[],"source":["album_info = await get_album_info('https://www.allmusic.com/album/long-may-you-run-mw0000197512#moodsThemes')\n","print(album_info)"]},{"cell_type":"markdown","metadata":{"id":"TqIs0Tsc3T0k"},"source":["### Get all informaton about songs and albums"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uoxMVPMcbQvP"},"outputs":[],"source":["\"\"\"\n","Asynchronous function to extract information about all songs from given album\n"," This function:\n","  1. Iterates through all_albums, which contains discography URLs of the given artists\n","  2. Fetches detailed information about the album by calling the function get_album_info().\n","  3. Fetches all songs from the given album by calling the function get_all_songs().\n","  4. Iterates through songs, and fetches detailed information about the songs by calling the function get_track_info().\n","  5. Stores results in a dictionary album_data, and then appends it to the list albums_data for each album\n","  6. Return a list albums_data containing all the extracted information\n","\"\"\"\n","async def get_artist_data(url):\n","    all_albums = await get_album(url)\n","    print('all albums')\n","    print(all_albums)\n","\n","    albums_data = []\n","\n","    for album_url in all_albums:\n","        print('current album url ' + album_url)\n","        album_info = await get_album_info(album_url + '#moodsThemes') # '#moodsThemes' anchor is added to ensure relevant sections of the album page are loaded\n","        songs = await get_all_songs(album_url)\n","\n","        tracks_data = []\n","\n","        for song_url in songs:\n","            track_info = await get_track_info(song_url + '#moodsThemes') # '#moodsThemes' anchor is added to ensure relevant sections of the album page are loaded\n","            tracks_data.append(track_info)\n","\n","        album_data = {\n","            'album' : album_info,\n","            'songs' : tracks_data\n","        }\n","        albums_data.append(album_data)\n","\n","    return albums_data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83394,"status":"ok","timestamp":1726844499784,"user":{"displayName":"Ana PetroviÄ‡","userId":"07204796382565449939"},"user_tz":-120},"id":"aQ7p0kzPyHql","outputId":"95b33206-d4b1-42e7-a29e-7aa895b5e059"},"outputs":[{"name":"stdout","output_type":"stream","text":["all albums\n","['https://www.allmusic.com/album/long-may-you-run-mw0000197512']\n","current album url https://www.allmusic.com/album/long-may-you-run-mw0000197512\n"]}],"source":["# albums_data = await get_artist_data('https://www.allmusic.com/artist/crosby-stills-nash-young-mn0000130036#discography')\n","# albums_data_david_crosby = await get_artist_data('https://www.allmusic.com/artist/david-crosby-mn0000644880#discography')\n","# albums_data_stephen_stills = await get_artist_data('https://www.allmusic.com/artist/stephen-stills-mn0000021744#discography')\n","# albums_graham_nash = await get_artist_data('https://www.allmusic.com/artist/graham-nash-mn0000153590#discography')\n","# albums_neil_young = await get_artist_data('https://www.allmusic.com/artist/neil-young-mn0000379125#discography')\n","# albums_crosby_nash = await get_artist_data('https://www.allmusic.com/artist/crosby-nash-mn0000846357#discography')\n","# albums_crosby_stills_nash = await get_artist_data('https://www.allmusic.com/artist/crosby-stills-nash-mn0000131581#discography')\n","albums_stills_young_band = await get_artist_data('https://www.allmusic.com/artist/stills-young-band-mn0002151611#discography')"]},{"cell_type":"markdown","metadata":{"id":"No9jJsu13dgR"},"source":["### Create DataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vCi4qhGybQvQ"},"outputs":[],"source":["\"\"\"\n","Function to create a DataFrame from the list of album data.\n","  This function:\n","  1. Iterates through albums_data, and extracts album details\n","  2. Iterates through songs in the current album's song list\n","  3. Creates dictionary 'row' which contains information about a track and its corresponding album\n","  4. Stores the results into a list data\n","  5. Creates DataFrame from the list, and returns the constructed DataFrame\n","\"\"\"\n","def create_dataframe(albums_data):\n","    data = []\n","\n","    for album_data in albums_data:\n","        album_info = album_data['album']\n","        for song_info in album_data['songs']:\n","            row = {\n","                'album_name': album_info['album_name'],\n","                'user_rating' : album_info['user_rating'],\n","                'album_release_date': album_info['album_release_date'],\n","                'album_duration': album_info['album_duration'],\n","                'album_genre': album_info['album_genre'],\n","                'album_styles': album_info['album_styles'],\n","                'album_recording_location': album_info['album_recording_location'],\n","                'album_recording_period': album_info['album-recording-date'],\n","                'album_moods': ', '.join(album_info['album_moods']),\n","                'album_themes': ', '.join(album_info['album_themes']),\n","                'track_name': song_info['track_name'],\n","                'composers': song_info['composers'],\n","                'genres': song_info['genres'],\n","                'styles': song_info['styles'],\n","                'moods': song_info['moods'],\n","                'themes': song_info['themes'],\n","            }\n","            data.append(row)\n","    df = pd.DataFrame(data)\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0e3Ab27yxsu"},"outputs":[],"source":["\n","# df_csny = create_dataframe(albums_data)\n","# df_david_crosby = create_dataframe(albums_data_david_crosby)\n","# df_stephen_stills = create_dataframe(albums_data_stephen_stills)\n","# df_graham_nash = create_dataframe(albums_graham_nash)\n","# df_neil_young = create_dataframe(albums_neil_young)\n","# df_crosby_nash = create_dataframe(albums_crosby_nash)\n","# df_crosby_stills_nash = create_dataframe(albums_crosby_stills_nash)\n","df_stills_young_band = create_dataframe(albums_stills_young_band)"]},{"cell_type":"markdown","metadata":{"id":"g9ntiG-P3gh_"},"source":["### Save DataFrame as .csv file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xobaj30YbQvQ"},"outputs":[],"source":["\"\"\"\n","Function to save a DataFrame to a CSV file\n","\"\"\"\n","def save_as_csv(df, filename):\n","    df.to_csv(filename, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ympiXZDyzfj"},"outputs":[],"source":["\n","# save_as_csv(df_david_crosby, 'allmusic/allmusic-david-crosby.csv')\n","# save_as_csv(df_stephen_stills, 'allmusic/allmusic-stephen-stills.csv')\n","# save_as_csv(df_graham_nash, 'allmusic/allmusic-graham-nash.csv')\n","# save_as_csv(df_neil_young, 'allmusic/allmusic-neil-young.csv')\n","# save_as_csv(df_crosby_stills_nash, 'allmusic/allmusic-crosby-stills-nash.csv')\n","save_as_csv(df_stills_young_band, 'allmusic-stills-young-band.csv')\n"]},{"cell_type":"markdown","metadata":{"id":"XUZHb10c3jd2"},"source":["### Combine all datasets to allmusic.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUegfvWZbQvQ"},"outputs":[],"source":["\"\"\"\n","Combine all datasets to allmusic.csv\n","\"\"\"\n","df_david_crosby = pd.read_csv('allmusic/allmusic-david-crosby.csv')\n","df_stephen_stills = pd.read_csv('allmusic/allmusic-stephen-stills.csv')\n","df_nash_graham = pd.read_csv('allmusic/allmusic-graham-nash.csv')\n","df_neil_young = pd.read_csv('allmusic/allmusic-neil-young.csv')\n","df_crosby_nash = pd.read_csv('allmusic/allmusic-crosby-nash.csv')\n","df_crosby_stills_nash = pd.read_csv('allmusic/allmusic-crosby-stills-nash.csv')\n","df_csny = pd.read_csv('allmusic/allmusic-csny.csv')\n","\n","df_allmusic = pd.concat([df_david_crosby, df_stephen_stills, df_nash_graham, df_neil_young, df_crosby_nash, df_crosby_stills_nash, df_csny])\n","print(df_allmusic)\n","\n","save_as_csv(df_allmusic, 'allmusic/allmusic.csv')\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"exploratory-analysis","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}